3. RAG（Retrieval Augmented Generation）とは
3.1 なぜRAGが必要か？（LLMだけの限界）
LLMは学習時点までの知識しか持っていない。

最新情報や会社独自の知識、個別データへの対応が苦手。

たとえば「今朝のニュース」「社内規定」などはLLM単体では答えられない。

3.2 RAGの基本アイデア
**RAG（検索拡張生成）**は、「外部知識」をLLMに組み合わせて答えを生成する技術。

やり方：

まず検索：
ユーザーの質問をベクトル化して、外部のデータベース（例：社内文書、論文DB、Web記事など）から関連情報を検索。

次に生成：
検索で得た情報＋元の質問をLLMに入力し、文脈に合った回答を生成。

3.3 ベクトル検索の仕組み
LLMと同様、**文書や質問を「ベクトル化」**して扱う。

**ベクトルの距離（コサイン類似度など）**を使い、意味的に近い文書を高速検索。

例：質問「生成AIの最新動向は？」→
関連する最新記事や論文をベクトル空間で発見

ベクトル検索の数式（コサイン類似度）
cos
⁡
(
𝜃
)
=
𝑎
⋅
𝑏
∣
∣
𝑎
∣
∣
×
∣
∣
𝑏
∣
∣
cos(θ)= 
∣∣a∣∣×∣∣b∣∣
a⋅b
​
 
$\mathbf{a}$：質問のベクトル

$\mathbf{b}$：文書のベクトル

値が1に近いほど「意味が近い」

3.4 RAG全体の流れ（図式）
css
コピーする
編集する
[ユーザー質問]
      ↓（ベクトル化）
[ベクトル検索]
      ↓（関連情報取得）
[LLMで回答生成]
      ↓
[回答出力]
3.5 RAGのメリットと応用
最新情報、独自データ、個別情報にも対応できる。

たとえば：

社内QA、マニュアル検索、論文要約、FAQ、法令検索、医療・製薬データ対応など。

LLM単体よりも「正確な情報」「根拠ある回答」がしやすい。

3.6 LLM × RAGのまとめ
LLM＝言語の理解と生成が得意

RAG＝必要な知識を外から取ってきて賢く使う

この組み合わせが「業務利用」「専門領域」など本格的なAI活用のカギ！

次章では、RAG/LLMの進化形として期待される「AIエージェント」の概念とフレームワークについて解説します。